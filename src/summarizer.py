#!/usr/bin/env python
# -*- coding: utf-8 -*-

# ==================================================================================================
# summarizer.py - Functions for text summarization
# ==================================================================================================
# ğŸ“¦ Built-in libraries
import re
import json
import urllib.parse
from datetime import datetime, timedelta
import os
import sys
from datetime import datetime
import nltk
# ğŸŒ Third-party libraries
import feedparser
from bs4 import BeautifulSoup
from transformers import pipeline
from newspaper import Article, ArticleException
import torch
import psutil  # ×ª×•×¡×™×£ ×œ×™×™×‘×•× ×× ×¢×“×™×™×Ÿ ××™×Ÿ
from nltk.tokenize import word_tokenize
import hashlib
import requests
from urllib.parse import urlparse
import html
import time
import urllib.parse




#1
def load_summarizer():
    try:
        if torch.cuda.is_available():
            print("ğŸš€ ××©×ª××© ×‘-GPU")
            return pipeline("summarization", model="facebook/bart-large-cnn", device=0)
        else:
            print("âš ï¸ GPU ×œ× ×–××™×Ÿ, ×¢×•×‘×¨ ×œ-CPU")
            return pipeline("summarization", model="facebook/bart-large-cnn", device=-1)
    except Exception as e:
        print(f"âš ï¸ GPU ×§×¨×¡, ×¢×•×‘×¨ ×œ-CPU: {e}")
        torch.cuda.empty_cache()  # × ×™×§×•×™ ×–×™×›×¨×•×Ÿ GPU
        return pipeline("summarization", model="facebook/bart-large-cnn", device=-1)


#2
def is_rss_summary_sufficient(text):
    """
    ×‘×•×“×§ ×× ×”×ª×§×¦×™×¨ ×-RSS ××¡×¤×§:
    - ××›×™×œ ×œ×¤×—×•×ª 20 ××™×œ×™×.
    - ××™× ×• ×¨×™×§ ××• ×§×¦×¨ ××“×™.
    """
    word_count = len(text.split())
    return word_count >= 20


summarizer_loaded = False  # ××©×ª× ×” ×’×œ×•×‘×œ×™ ×œ×‘×“×™×§×ª ×˜×¢×™× ×ª ×”××•×“×œ
#3
def summarize_text(text, title=""):
    global summarizer, summarizer_loaded

    try:
        # ×‘×“×™×§×” ×× ×”××•×“×œ × ×˜×¢×Ÿ ×›×‘×¨
        if not summarizer_loaded or summarizer is None:
            print("âš ï¸ ×”××•×“×œ ×œ× × ×˜×¢×Ÿ, ×˜×•×¢×Ÿ ××—×“×©...")
            summarizer = load_summarizer()
            summarizer_loaded = True

        if not text.strip():
            print("âš ï¸ ×˜×§×¡×˜ ×¨×™×§.")
            return ""

        # ×× ×”×˜×§×¡×˜ ×§×¦×¨ ×-30 ××™×œ×™× - ××—×–×™×¨ ××•×ª×• ×›××• ×©×”×•×
        original_word_count = len(text.split())
        if original_word_count < 30:
            print(f"âœ… ×˜×§×¡×˜ ×§×¦×¨ ({original_word_count} ××™×œ×™×), ×œ× ××‘×¦×¢ ×¡×™×›×•×.")
            return text

        # ××•×¡×™×£ ××ª ×”×›×•×ª×¨×ª ×›×”× ×—×™×” ×¡××•×™×™×”
        if title:
            text = f"{title}. {text}"

        # ×—×™×ª×•×š ×”×˜×§×¡×˜ ×œ-500 ××™×œ×™× ×œ×›×œ ×”×™×•×ª×¨
        if original_word_count > 500:
            text = " ".join(text.split()[:500])

        max_length = min(200, original_word_count * 2)
        min_length = max(20, max_length // 2)

        print(f"ğŸ¤– ××‘×¦×¢ ×¡×™×›×•× ×¢×œ {len(text.split())} ××™×œ×™× ×¢× max_length={max_length}, min_length={min_length}...")
        summary = summarizer(text, max_length=max_length, min_length=min_length, do_sample=False)

        if summary and summary[0]['summary_text'].strip():
            summarized_text = summary[0]['summary_text'].strip()
            word_count = len(summarized_text.split())
            print(f"âœ… × ×•×¦×¨ ×ª×§×¦×™×¨ ×‘××•×¨×š {word_count} ××™×œ×™×.")
            return summarized_text
        else:
            print("âš ï¸ ×”×ª×§×¦×™×¨ ×¨×™×§ â€“ fallback.")
            return ""

    except NameError as ne:
        print(f"âš ï¸ ×‘×¢×™×” ×¢× ×”××•×“×œ (×œ× × ××¦×): {ne}")
        summarizer_loaded = False  # ××¡××Ÿ ×©×”××•×“×œ ×œ× ×–××™×Ÿ
        return summarize_text(text, title)  # ×× ×¡×” ×©×•×‘ ×œ××—×¨ ××ª×—×•×œ

    except Exception as e:
        print(f"ğŸ”¥ ×©×’×™××” ×‘×¡×™×›×•×: {e}")
        torch.cuda.empty_cache()
        summarizer_loaded = False  # ××¡××Ÿ ×©×”××•×“×œ ×œ× ×–××™×Ÿ
        return ""


